---
title: "Introducción a las Deep Complex Networks"
author: "JJ Merelo"
date: "9 de mayo de 2018"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
bibliography: deepgraph.bib
---

Un grafo es un conjunto de nodos y aristas que expresan algún tipo de relación entre esos nodos. Se habla de redes complejas  [@strogatz2001exploring] cuando estos grafos tienen una serie de características que implican que el sistema que representan es un sistema complejo, principalmente existencia de redes de potencias [@newman2005power] y de la característica *mundo pequeño* [@watts1998collective]. En particular, se habla de redes sociales cuando o los nodos o las aristas expresan unidades o relaciones sociales [@mislove2007measurement]. En general, las redes sociales suelen ser redes complejas, al menos cuando alcanzan un cierto tamaño, y el hecho de que se comporten como sistemas complejos acarrea una serie de consecuencias con respecto a su resistencia a ataques [@albert2000error] y patrones de crecimiento [@newman2005power], así como la creación de una serie de mesoestructuras y patrones comunes [@milo2002network] y transiciones de fase [@milo2002network] precedidas por un estado crítico al que se llega, generalmente, por autoorganización. Este estado de criticalidad auto-organizada [@bak2013nature]. La autoorganización explica que muchos sistemas naturales se encuentren en este estado crítico que provoca la existencia de leyes de potencias, pero también otros fenómenos como el llamado *ruido rosa* y correlaciones a larga distancia entre diferentes eventos.

El estudio de las redes complejas en todos sus aspectos sufrió una gran expansión desde finales de los 90, coincidiendo con el auge de la World Wide Web. Este auge estuvo acompañado de una gran cantidad de herramientas para analizar, visualizar y calcular en grafos. Con la existencia de multitud de herramientas, se han usado las redes como modelo de una gran variedad de sistemas complejos: genomica [@park2015deep], modelos de redes de transporte [@ma2015] y de sistemas de regulación de tráfico con semáforos [@goel2017] o el conectoma o patrones de conexión cerebral humanos [@sporns2005human]; el estado crítico y modelos autoorganizativos han sido detectados en gran cantidad de sistemas, desde redes de citas [@leydesdorff2018discontinuities,@benjafield2017between], hasta equipos de desarrollo de software [@gorshenev2004punctuated], ambos dos procesos de creación de conocimiento cuya criticalidad también ha sido examinada por diferentes autores [@tadic2017mechanisms]; estos procesos también se han encontrado en la polución aérea [@shi2009self] y el tráfico en la red [@nagel1996network].

En el pasado, los solicitantes de este proyecto han aplicado teoría de redes a múltiples campos. El primer uso de redes complejas en el análisis de un sistema se hizo sobre la red de coautorías del campo de computación evolutiva [@redes-arxiv,@ec-network-2006,@merelo2007bce], la red de páginas web de las empresas del IBEX [@ibex2015], la de tesis doctorales en diferentes áreas, como bibliometría [@lopez2006analisis] o los blogs de esa misma área [@TORRESSALINAS2011168]; también la red de pases de la selección española [@futbol2005,@futbol2011], ambos en el año 2005. En estos dos trabajos se usaron herramientas computacionales y medidas de análisis similares, pero había varios retos que necesitaron una solución ad hoc: la extracción de datos y la asignación de propiedades y elementos de los sistemas originales a un grafo sobre el que llevar a cabo el análisis. Cualquier sistema tiene múltiples elementos, y aunque en una red de pases puede parecer obvio que deben ser los jugadores los nodos y los pases las aristas, otras combinaciones, como usar zonas del campo o el tipo de jugador, son a priori posibles. La captación de información es totalmente ad hoc, e incluye heurísticas para reconocer a los jugadores o herramientas de *scraping* para extraer información de páginas web.

Estudios más recientes hechos por nuestro grupo revelan también ciertos efectos de red [@wikipedia17], pero sin que la red compleja de la que emergen sea evidente o clara. Por ejemplo, en estudios de repositorios de código [@soc17] se encuentran efectos de criticalidad autoorganizada aunque haya un sólo, o unos pocos, usuarios. Resulta necesario, por tanto, realizar algún tipo de estudio sistemático de diferentes descripciones del sistema para elegir el modelo de red que se mejor explique los efectos que se observan. En el estudio sobre diferentes repositorios [@repo17], se encuentran efectos de esa criticalidad organizada, pero los modelos de red parten de diferentes supuestos; sin embargo, en estudios como el de Herráiz y colaboradores [@Herraiz08], no se encuentran correlaciones a larga distancia y eso se puede deber tanto a la representación del modelo como a la escala temporal considerada. 

En general, no hay nunca una forma *natural* de representar la red subyacente en un fenómeno o un sistema, de la misma forma que no hay una forma *natural* de representar los datos de un problema para aplicarle sistemas de reconocimiento o predicción. Sin embargo, el enfoque denominado *Deep Learning* [@lecun2015deep] crea diferentes capas de procesamiento de los datos iniciales que permiten crear una representación del problema intermedia, más fácil de abordar pero sobre todo, que se lleve a cabo de forma automática. 
Este enfoque es el que nosotros pretendemos aplicar en este proyecto, pero trabajando sobre información reticular, es decir, en forma de red, en vez de trabajar sobre información tabular, en forma de tablas, que es lo que el enfoque Deep Learning lleva a cabo; este enfoque continúa el del proyecto EphemeCH [@ECTA2015cotta] y se centran en un aspecto, los grafos, de lo que se tratará en el futuro proyecto DeepBio (concecido provisionalmente por el Ministerio). En todo caso, el enfoque de optimización ha sido aplicado por nuestro grupo a la optimización de redes neuronales, un tipo de grafo que en algunos casos se comporta como red compleja, en una línea de investigación que comenzó a principios de los 90 [@glvq95] y ha continuado hasta la actualidad [@castilloCEC99,@parras2016radial]. Se trata de un enfoque, el de creación de varias *capas* de procesamiento y optimización, tal como se propone en el campo de Deep Learning actualmente. En este proyecto se trataría de aplicar al caso de grafos y la modelización de sistemas que se puedan representar mediante grafos.

Tampoco existe una forma *natural* de visualizarlo. Aparte de las herramientas ya existentes en el área como Gephi o Paje, se han propuesto nuevos métodos de visualización que usan métodos como el biplot [@torres2013use] o las redes neuronales [@blogtalk2jj] y que pueden incluso reflejar la evolución de un grafo complejo [@weblogs-JNCA]; hay empresas como Graphext dedicadas a la visualización en modo grafo de diferentes cantidades, pero en la mayor parte de los casos se trata de esfuerdos ad hoc y cuya interpretación en algunos casos está totalmente separada del modelo de grafo subyacente y, por tanto, no permite realmente evaluar diferentes modelos o compararlos. Los métodos de visualización, además, son computacionalmente complejos y en cualquier caso pueden requerir de técnicas de optimización adicionales para que se ejecuten de forma eficiente. 

Para llevar a cabo este enfoque se propone investigar tanto técnicas de optimización como usar técnicas de Deep Learning para cambiar representación. Ya ha habido varios investigadores que han aplicado Deep Learning a grafos, por ejemplo para predecir atascos de tráfico [@ma2015] o para predicción en redes genómicas [@park2015deep], pero se han centrado más en obviar el modelo reticular para trabajar directamente sobre datos tabulares. El contar con el grafo subyacente permitirá no sólo hacer predicciones o clasificaciones, sino también tener un modelo más efectivo del sistema que pueda usarse como ayuda en la toma de decisiones.






## Referencias

